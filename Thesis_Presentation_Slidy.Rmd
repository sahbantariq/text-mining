---
title: "Social Media Mining with R"
output: slidy_presentation
author: Sahban Tariq Malik
date: 13th June, 2018
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

Introduction
========================================================

- Data mining is the process of extracting useful information from large set of any raw data. 
- Text mining is a branch of data mining in which raw data is in the textual format.  
- Social media mining is a branch of text mining in which social media data is used. 
- R is a programming language with a statistical software environment used to analyze data efficiently.

Features of Textual Data
========================================================

- Collection of Document
    - A collection of documents is a group of similar text-based documents.
    - The reviews of a tourism brand altogether become a collection of documents.
- Document
    - A collection of words that represents a unit within a document collection. 
- Document Features
    - Character
    - Word
    - Term
    - Concepts
  
Social Media Data Structure
========================================================

Methodology
========================================================
![Methodology](Thesis_Presentation-figure/01-img-methodology.png)

- The study builds reuseable R functions for these techniques. 

Data 
========================================================
- Turkish Airlines “Türk Hava Yolları” is one of the most famous Turkish brands worldwide.
- Company's Facebook posts and its comments, likes and shares are extracted for six months, i.e. from 15 March 2017 to 15 October 2017.
- A total of 6,846 reviews of Turkish airlines are extracted from 686 pages in TripAdvisor, i.e. from January 2016 to April 2018. 

Text Mining
========================================================

- Collection of Document
- Document
- Document Structure
- Document Features
  - Character
  - Word
  - Term
  - Concepts

Social Media Mining
========================================================

- Bullet 1
- Bullet 2
- Bullet 3

Methodology
========================================================

- Data Extraction
- Data Wrangling
- Tokenization
- Data Cleaning
- Analysis

Data Extraction
========================================================

```{r auth, eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE}
# Facebook Authorization
fb_oauth <- Rfacebook::fbOAuth(
  app_id="1380496555352781",
  app_secret="eb3abc...",
  extended_permissions = TRUE)

# Saving variable fb_oauth 
save(fb_oauth, file="fb_oauth")

# Extract posts from turkish airlines page
turkishairlines <- 
  Rfacebook::getPage(
    page = "turkishairlines",
    token = fb_oauth, n = 2000)

# Save the posts in R data file
saveRDS(turkishairlines, "turkishairlines_2000")
```

Data Extraction
========================================================
```{r fb_data_id, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
```
```{r show_data, echo=FALSE, message=FALSE, warning=FALSE}
# Read R data file and store in new variable
data_turkishairlines <- readRDS("turkishairlines_2000")

# Storing the post ids in a new variable
data_turkishairlines_id <- data_turkishairlines$id

# Viewing limited variables and rows
data_turkishairlines %>% 
  dplyr::select(from_id, likes_count, type, comments_count, 
                shares_count, message) %>% 
  tibble::as_tibble() %>% 
  head(2)

data_turkishairlines %>% 
  dplyr::select(message) %>% 
  tibble::as_tibble() %>% 
  head(2)
```
Data Extraction
========================================================
```{r savingcommentsdata, echo=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
# Extracting comments and reactions from the extracted posts
all_posts <- data_turkishairlines_id[1:300] %>% 
  lapply(getPost, n = 50000, token=fb_oauth, 
         comments = TRUE, reactions = TRUE)

# Save first 300 posts comments in a R data file.
saveRDS(all_posts, "300_posts")
```

Data Extraction
========================================================
```{r datawrangling of facebookdata, echo=TRUE, message=FALSE, warning=FALSE}
# Reading the saved RDS file instead of applying getPost function repeatedly.
threehundred_posts <- readRDS("300_posts") 

# Saving comments for first post in new variable
full_comments <- threehundred_posts[[1]]$comments$message %>%
  as.data.frame() %>% 
  setNames("comments") %>%
  dplyr::mutate(id = data_turkishairlines_id[1])

# Expanding full_comments by adding comments of remaining posts. 
for (i in 1:299) {
  comment <- threehundred_posts[[i+1]]$comments$message %>% 
    as.data.frame() %>% 
    setNames("comments") %>%
    dplyr::mutate(id = data_turkishairlines_id[i+1])
  full_comments = rbind(full_comments, comment)
}

# Assigning the post ids to its comments. 
# The posts ids are repeated when there are more than one comment.  
full_comment_post <- full_comments %>% 
  dplyr::left_join(data_turkishairlines, by = "id")

# Saving the comments of posts in R data file. 
saveRDS(full_comment_post, "300_posts_comments")
```
```{r readingcomments}
readRDS("300_posts_comments") %>% 
  subset(select = c(3,1,2,4,5,6,7,8,9,10)) %>% 
  tibble::as_tibble() %>% 
  head(5)

readRDS("300_posts_comments") %>% 
  dplyr::select(comments) %>% 
  tibble::as_tibble() %>% 
  head(2)
```

Data Extraction
========================================================
```{r tripadvisor, echo=FALSE, eval=FALSE, message=FALSE, warning=FALSE}
library("rvest")

url <- "https://www.tripadvisor.com/Airline_Review-d8729174-Reviews-Turkish-Airlines"
url <- "https://www.tripadvisor.com/Airline_Review-d8729174-Reviews-or20-Turkish-Airlines#REVIEWS"

df_total = data.frame()

for (i in seq(0, 20050, 10))
{
  if (i == 0) {
    url <- "https://www.tripadvisor.com/Airline_Review-d8729069-Reviews-Emirates"
  }
  
  else  {
    url <- paste(
      "https://www.tripadvisor.com/Airline_Review-d8729069-Reviews-or",i,"-Emirates#REVIEWS", 
      sep = "")
  }
  
  reviews <- url %>%
    read_html() %>%
    html_nodes("#REVIEWS .innerBubble")
  
  id <- reviews %>%
    html_node(".quote a") %>%
    html_attr("id")
  
  quote <- reviews %>%
    html_node(".quote span") %>%
    html_text()
  
  rating <- reviews %>%
    html_node(".rating .rating_s_fill") %>%
    html_attr("alt") %>%
    gsub(" of 5 stars", "", .) %>%
    as.integer()
  
  date <- reviews %>%
    html_node(".rating .ratingDate") %>%
    html_attr("title") %>%
    strptime("%b %d, %Y") %>%
    as.POSIXct()
  
  review <- reviews %>%
    html_node(".entry .partial_entry") %>%
    html_text()
  
  df <- data.frame(id, quote, rating, date, review, stringsAsFactors = FALSE)
  df_total <- rbind(df_total, df)
}

# Save an object to a file
saveRDS(df_total, file = "tripadvisor_turkishairlines6846.rds")
```
```{r readingtripadvisordata}
trip_turkishairlines <- readRDS(file = "tripadvisor_turkishairlines6846.rds")

trip_turkishairlines %>%
  dplyr::select(id, date, quote, review) %>% 
  tibble::as_tibble() %>% 
  head(5)

trip_turkishairlines %>% 
  dplyr::select(review) %>% 
  tibble::as_tibble() %>% 
  dplyr::sample_n(3)
```

Data Cleaning
========================================================
```{r cleaning, echo=TRUE, message=FALSE, warning=FALSE}
library(tidytext)
data(stop_words)
# Custom stop words
custom_stop_words <- data.frame(word = c("miss", "flight", "tukish", 
                                         "airlines", "flights", 
                                         "airline", "turkish", "de"), 
                                lexicon = c("custom")) %>%
  rbind(stop_words)

# Convert non_base verbs into base verbs

extract_non_base <- function(data) {
  data %>%
    dplyr::rename(non_base = word) %>%
    dplyr::left_join(readRDS("sahban_base_lexicon"), by = "non_base") %>%
    dplyr::mutate(base = ifelse(is.na(base), non_base, base)) %>%
    dplyr::rename(word = base) %>%
    dplyr::select(-one_of("non_base")) 
}

# Convert Plurals to Singular Noun

extract_plural <- function(data) {
  data %>% 
    dplyr::rename(plural = word) %>% 
    dplyr::left_join(readRDS("sahban_noun_lexicon"), by = "plural") %>% 
    dplyr::mutate(noun = ifelse(is.na(noun), plural, noun)) %>% 
    dplyr::rename(word = noun) %>% 
    dplyr::select(-one_of("plural"))
}
```


Tokenization
========================================================

```{r tokenization, echo=FALSE, message=FALSE, warning=FALSE}
# Custom stop words
custom_stop_words <- data.frame(word = c("miss", "flight", "tukish", 
                                         "airlines", "flights", 
                                         "airline", "turkish", "de"), 
                                lexicon = c("custom")) %>%
  rbind(stop_words)
```
```{r tokenization1, echo=TRUE, message=FALSE, warning=FALSE}
tokenize <- function(file, data_type) {
  data_tibble <- readRDS(file = file) %>% 
    tibble::as_tibble()
  
  data_vector <- data_tibble %>% 
    dplyr::pull(data_type) %>% 
    iconv(from = "UTF-8", to = "Latin1")
  
  tokens <- tibble::as_tibble(data_vector) %>% 
    dplyr::filter(!is.na(value)) %>% 
    dplyr::mutate(response_number = rownames(.)) %>% 
    dplyr::select(response_number, value) %>% 
    tidytext::unnest_tokens(word, value)
  
  tokens
}
```

Tokenization
========================================================

```{r tokenized, echo=TRUE, message=FALSE, warning=FALSE}
facebook_tokens <- tokenize("300_posts_comments", "comments") %>% 
  extract_non_base() %>% 
  extract_plural()

tripadvisor_tokens <- tokenize("tripadvisor_turkishairlines6846.rds", "review") %>% 
  extract_non_base() %>% 
  extract_plural()
```

``` {r saving, eval=FALSE, message=FALSE, warning=FALSE}
saveRDS(tokens_count, "tokens_count_300")
saveRDS(tokens_count, "TA_tokens_count_6846")
```
```{r readtokens, message=FALSE, warning=FALSE}
facebook_tokens %>% 
  tibble::as_tibble()

tripadvisor_tokens %>% 
  tibble::as_tibble()
```

Word Count
========================================================
``` {r wordcount, message=FALSE, warning=FALSE}

word_count <- function(data) {
  readRDS(data) %>% 
    dplyr::anti_join(custom_stop_words, by = "word") %>% 
    dplyr::count(word, sort = TRUE) %>% 
    tibble::as_tibble()
}

facebook_word_count <- word_count("facebook_tokens")
tripadvisor_word_count <- word_count("tripadvisor_tokens")

facebook_word_count
tripadvisor_word_count
```

Word Count Plot
========================================================
```{r wordcountplot, echo=TRUE, message=FALSE, warning=FALSE}

word_count_plot <- function(data, min_count) {
  tokens_count <- readRDS(data)
  
  tokens_count %>% 
    dplyr::anti_join(custom_stop_words) %>% 
    dplyr::filter(n > min_count) %>%
    dplyr::mutate(word = reorder(word, n)) %>%
    ggplot2::ggplot(mapping = ggplot2::aes(word, n)) +
    ggplot2::geom_col() +
    ggplot2::xlab("Most Frequent Words") + 
    ggplot2::coord_flip()
}

word_count_plot("tokens_count_300", 25)
word_count_plot("TA_tokens_count_6846", 300)
```  

Indexed Tokenization
========================================================
```{r numbered_response_tokens, echo=FALSE, message=FALSE, warning=FALSE}

numbered_response_tokens <- function(file, response_type) {
  
  dataset <-  readRDS(file = file)
  
  dataset %>% 
    tibble::as_tibble() %>% 
    dplyr::mutate(response_type = 
                    iconv(pull(., response_type), 
                          from = "UTF-8", to = "Latin1")) %>% 
    dplyr::mutate(post_number = as.numeric(factor(id))) %>% 
    dplyr::group_by(id) %>% 
    dplyr::mutate_if(is.factor, as.character)
}
```

```{r numbererd_tokenization, echo=FALSE, message=FALSE, warning=FALSE}
tidy_response_facebook <- 
  numbered_response_tokens("300_posts_comments", "comments") %>% 
  dplyr::mutate(comment_number = row_number()) %>% 
  dplyr::select(id, post_number, response_number = comment_number, 
                comments, created_time, type, likes_count, comments_count, 
                shares_count) %>% 
  tidytext::unnest_tokens(word, comments) %>% 
  dplyr::anti_join(custom_stop_words) %>% 
  extract_non_base() %>% 
  extract_plural()

tidy_response_tripadvisor <- 
  numbered_response_tokens("tripadvisor_turkishairlines6846.rds", "review") %>% 
  dplyr::select(id, response_number = post_number, review, quote, rating, date) %>% 
  tidytext::unnest_tokens(word, review) %>% 
  dplyr::anti_join(custom_stop_words) %>% 
  extract_non_base() %>% 
  extract_plural()

tidy_response_facebook %>% 
  tibble::as_tibble() %>% 
  dplyr::select(post_number, response_number, word, type) %>% 
  subset(select = c(2,3,4,5))

tidy_response_tripadvisor %>% 
  tibble::as_tibble() %>% 
  dplyr::select(id, response_number, word) %>% 
  dplyr::arrange(response_number)
```

Sentence Tokenization
========================================================
```{r sentencetokens1, eval=FALSE, message=FALSE, warning=FALSE}
untidy_response_facebook <- 
  numbered_response_tokens("300_posts_comments", "comments") %>% 
  dplyr::mutate(comment_number = row_number()) %>% 
  dplyr::select(id, post_number, comment_number, comments, 
                created_time, type, likes_count, comments_count, 
                shares_count)
```
```{r sentencetokens2, eval=FALSE, message=FALSE, warning=FALSE}
untidy_response_tripadvisor <- 
  numbered_response_tokens("tripadvisor_turkishairlines6846.rds", "review") %>% 
  dplyr::select(id, post_number, review, quote, rating, date)

```
```{r sentencetokens3, eval=FALSE, message=FALSE, warning=FALSE}
sentence_tokens <- function(data = untidy_response_facebook, 
                            response_column = "comments", 
                            group_by = "comment_number") {
  # English Dictionary
  qdapDictionaries::DICTIONARY[,1]
  
  en_word_comments <- data %>% 
    dplyr::ungroup() %>% 
    tidytext::unnest_tokens_("word", response_column) %>% 
    dplyr::filter(word %in% qdapDictionaries::DICTIONARY[,1])
  
  en_word_sentence_comments <- en_word_comments %>% 
    dplyr::group_by_("id", group_by) %>% 
    dplyr::mutate(sentence = paste(word, collapse = " ")) %>%
    dplyr::distinct(sentence, .keep_all = TRUE) %>% 
    dplyr::as_data_frame() %>% 
    dplyr::mutate(sentence = iconv(sentence, to = 'latin1')) %>% 
    dplyr::ungroup()
  
  # Sentence as tokens with post number and comment number
  
  en_word_sentence_comments %>% 
    dplyr::select_("id", group_by, "sentence") %>%
    dplyr::ungroup() %>% 
    tidytext::unnest_tokens(sentences, sentence, token = "sentences")
}
```
```{r sentencetokens4, eval=FALSE, message=FALSE, warning=FALSE}
facebook_sentence_tokens <- 
  sentence_tokens(data = untidy_response_facebook,
                  response_column = "comments",
                  group_by = "comment_number")

tripadvisor_sentence_tokens <- 
  sentence_tokens(data = untidy_response_tripadvisor,
                  response_column = "review",
                  group_by = "post_number")
```
```{r sentencetokens5, eval=FALSE, message=FALSE, warning=FALSE}
facebook_sentence_tokens 

tripadvisor_sentence_tokens

tripadvisor_sentence_tokens
  dplyr::select(sentences) 
```

Sentiment Analysis
========================================================

```{r response_sentiments, echo=TRUE, message=FALSE, warning=FALSE}

response_sentiments <- function(data, lexicon, group_by = sentiment) {
  data %>% 
    dplyr::inner_join(get_sentiments(lexicon), by = "word") %>% 
    dplyr::count(response_number, sentiment) %>% 
    tidyr::spread(sentiment, n, fill = 0) %>% 
    dplyr::mutate(sentiment = positive - negative) %>% 
    dplyr::ungroup()
}
```
```{r response_sentiments1, echo=TRUE, message=FALSE, warning=FALSE}
# bing
facebook_sentiments_bing <- response_sentiments(tidy_response_facebook, "bing")
tripadvisor_sentiments_bing <- response_sentiments(tidy_response_tripadvisor, "bing")
```
```{r response_sentiments2, echo=TRUE, message=FALSE, warning=FALSE}
# nrc
facebook_sentiments_nrc <- response_sentiments(tidy_response_facebook, "nrc")
tripadvisor_sentiments_nrc <- response_sentiments(tidy_response_tripadvisor, "nrc")
```
```{r response_sentiments3, echo=TRUE, message=FALSE, warning=FALSE}
#afinn
sentiments_afinn <- function(data) {
  data %>% 
    dplyr::ungroup() %>% 
    dplyr::inner_join(tidytext::get_sentiments("afinn"), by = "word") %>% 
    dplyr::group_by(id, response_number) %>% 
    dplyr::summarise(score = sum(score)) 
}
```
```{r response_sentiments4, echo=TRUE, message=FALSE, warning=FALSE}
facebook_sentiments_afinn <- sentiments_afinn(tidy_response_facebook)
tripadvisor_sentiments_afinn <- sentiments_afinn(tidy_response_tripadvisor)
```
```{r response_sentiments5, echo=TRUE, message=FALSE, warning=FALSE}
facebook_sentiments_bing %>% 
  dplyr::select(response_number, negative, positive, sentiment) 
tripadvisor_sentiments_bing 
facebook_sentiments_nrc 
tripadvisor_sentiments_nrc 
facebook_sentiments_afinn 
tripadvisor_sentiments_afinn
```

Sentiments to All Words Ratio
========================================================
```{r sentimentratio, message=FALSE, warning=FALSE}
sentiment_token_ratio <- function(data, sentiment_type = "negative") {
  
  negative_sentiment <- get_sentiments("bing") %>% 
    dplyr::filter(sentiment == sentiment_type)
  
  wordcounts <- data %>% 
    dplyr::group_by(response_number) %>%
    dplyr::summarize(word = n())
  
  data %>%
    dplyr::semi_join(negative_sentiment) %>%
    dplyr::group_by(id, response_number) %>%
    dplyr::summarize(negativewords = n()) %>%
    dplyr::left_join(wordcounts, by = c("response_number")) %>%
    dplyr::mutate(ratio = negativewords/word) %>%
    dplyr::top_n(10) %>%
    dplyr::ungroup() %>% 
    dplyr::arrange(desc(ratio))
}

facebook_negative_sentiment_ratio <- 
  sentiment_token_ratio(tidy_response_facebook, "negative")
tripadvisor_negative_sentiment_ratio <- 
  sentiment_token_ratio(tidy_response_tripadvisor, "negative")

facebook_positive_sentiment_ratio <- 
  sentiment_token_ratio(tidy_response_facebook, "positive")
tripadvisor_positive_sentiment_ratio <- 
  sentiment_token_ratio(tidy_response_tripadvisor, "positive")

facebook_negative_sentiment_ratio
tripadvisor_negative_sentiment_ratio

numbered_response_tokens(
  "tripadvisor_turkishairlines6846.rds", "review") %>% 
  dplyr::select(id, response_number = post_number, review, 
                quote, rating, date) %>% 
  dplyr::filter(response_number == 4976) %>% 
  dplyr::select(review, id)
```

Most Frequent Sentiments
========================================================

```{r frequentsentiments, message=FALSE, warning=FALSE}
frequent_sentiments <- function(data) {
  data %>% 
    dplyr::inner_join(tidytext::get_sentiments("bing")) %>% 
    dplyr::ungroup() %>% 
    dplyr::count(word, sentiment, sort = TRUE)
}

facebook_frequent_sentiments <- frequent_sentiments(tidy_response_facebook)
tripadvisor_frequent_sentiments <- frequent_sentiments(tidy_response_tripadvisor)

facebook_frequent_sentiments
tripadvisor_frequent_sentiments

```

Plot Frequent Sentiments Counts
========================================================
```{r plotsentimentcount, message=FALSE, warning=FALSE}

plot_sentiment_count <- function(data) {
  data %>% 
    dplyr::group_by(sentiment) %>% 
    dplyr::top_n(10) %>% 
    dplyr::ungroup() %>% 
    dplyr::mutate(word = reorder(word, n)) %>% 
    ggplot2::ggplot(ggplot2::aes(word, n, fill = sentiment)) +
    ggplot2::geom_col(show.legend = FALSE) +
    ggplot2::facet_wrap(~sentiment, scales = "free_y") +
    ggplot2::labs(y = "Frequent Sentiments",
                  x = "Frequency") +
    ggplot2::coord_flip()
}

plot_sentiment_count(facebook_frequent_sentiments)
plot_sentiment_count(tripadvisor_frequent_sentiments)
```

Word Cloud
========================================================
```{r wordcloud, message=FALSE, warning=FALSE}
library(wordcloud)
word_cloud <- function(data, max_words) {
  data %>%
    dplyr::ungroup() %>% 
    dplyr::count(word) %>%
    with(wordcloud::wordcloud(word, n, max.words = max_words))
}

word_cloud(tidy_response_facebook, max_words = 50)
word_cloud(tidy_response_tripadvisor, max_words = 75)
```

Sentiment Cloud
========================================================

```{r sentimentcloud, message=FALSE, warning=FALSE}
library(reshape2)

sentiment_cloud <- function(dataset) {
  dataset %>%
    dplyr::inner_join(tidytext::get_sentiments("bing")) %>%
    dplyr::count(word, sentiment, sort = TRUE) %>%
    reshape2::acast(word ~ sentiment, value.var = "n", fill = 0) %>%
    wordcloud::comparison.cloud(colors = c("#F8766D", "#00BFC4"),
                                max.words = 100)
}

sentiment_cloud(tidy_response_facebook)
sentiment_cloud(tidy_response_tripadvisor)
```



Data Wrangling
========================================================

- Bullet 1
- Bullet 2
- Bullet 3

Tokenization
========================================================

- Word Tokenization
- N-gram Tokenization
- Sentence Tokenization

Data Cleaning
========================================================

- Stop Words
- Multiple Verb Forms
- Plural Nouns

Word Frequency
========================================================

- Bullet 1
- Bullet 2
- Bullet 3


Sentiment Analysis
========================================================

- Bullet 1
- Bullet 2
- Bullet 3


Sentiment Lexicons
========================================================

- AFINN
- Opinion Lexicon
- Emolex

AFINN
========================================================

- Bullet 1
- Bullet 2
- Bullet 3


Opinion Lexicon
========================================================

- Bullet 1
- Bullet 2
- Bullet 3

Emolex
========================================================

- Bullet 1
- Bullet 2
- Bullet 3

Most Frequent Sentiment
========================================================

- Bullet 1
- Bullet 2
- Bullet 3

Sentiments to All Words Ratio
========================================================

- Bullet 1
- Bullet 2
- Bullet 3

Word Cloud
========================================================

- Bullet 1
- Bullet 2
- Bullet 3

Sentiment Cloud
========================================================

- Bullet 1
- Bullet 2
- Bullet 3


Code
========================================================

```{r}
summary(cars)
```

Slide With Plot
========================================================

```{r, echo=FALSE}
plot(cars)
```
